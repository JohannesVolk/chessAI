{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import chess\n",
    "from network import ChessBoardEvalNN\n",
    "from data.dataset import ChessPositionsDataset\n",
    "from data.database import Database\n",
    "\n",
    "import data.database\n",
    "\n",
    "%load_ext autoreload\n",
    "# %load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following converts a number games from the specified pgn file to the individual positions.\n",
    "The positions will be one hot encoded and stored in the database.\n",
    "\n",
    "For each type of piece a 8x8 matrix is used and if a respective piece is located on a square it is assigned a 1 and else 0.\n",
    "Due to sparsity we store this data in sparse format by only storing indicies.\n",
    "All positions are mirrored to be from the perspective of the white player as this makes training easier for the DNN as it only has to learn to play from one perspective.\n",
    "\n",
    "We only extract the games which where annotated by a engine before as this takes a lot of computational ressources to do.\n",
    "We normalize and translate the scores into an interval from -1 and 1 (where 1 indicates an advantage for black and 1 for white).\n",
    "\n",
    "\n",
    "We keep track (by hashing) which games already are stored and therefore dont allow them to be processed and stored multiple times.\n",
    "\n",
    "NOTE: This process takes a lot of time (on my device ~1h per 100_000 games)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Database() as db:\n",
    "    db.store_positions_from_pgn_file(\"./data/pgn/comp-2019-03.pgn\", num_games = 300_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many different games we have currently stored and how many positions they contain.\n",
    "\n",
    "-> we make sure every position is only stored once as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with Database() as db:\n",
    "    count = db.cur.execute(\"SELECT COUNT(*) FROM games\").fetchone()[0]\n",
    "    print(f\"{count} games stored\")\n",
    "    count = db.cur.execute(\"SELECT COUNT(*) FROM positions\").fetchone()[0]\n",
    "    print(f\"{count} positions stored\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now lets create a Dataset to be used for training.\n",
    "\n",
    "The ChessPostionsDataset accesses the SQLite database in a dynamic (load as you use) and therefore the memory consumption on the GPU for training is managable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChessPositionsDataset(num_positions = 8_414_441)\n",
    "\n",
    "# maybe inspect how one dataelement looks like\n",
    "# print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split our data into different sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set, train_set = torch.utils.data.random_split(dataset, [414_441, 8_000_000], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look how the evalutations are distributed. Looks like a normal distribution. Nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.displot(dataset.get_all_evaluations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our training process and our model.\n",
    "\n",
    "We use PyTorch Lightning as it eases up the whole process and makes it less complicated.\n",
    "\n",
    "We also log the whole process with TensorBoard to better understand whats going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "hparams = {\"learning_rate\": 1e-3}\n",
    "\n",
    "# create a new model\n",
    "model : ChessBoardEvalNN = ChessBoardEvalNN(hparams=hparams)\n",
    "\n",
    "# OR: import a previous version already trained some weights) of the model\n",
    "# model = ChessBoardEvalNN.load_model(hparams)\n",
    "\n",
    "logger = TensorBoardLogger(\"./tb_logs\", name=\"ChessNN\", default_hp_metric=False, log_graph=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else None,\n",
    "    logger = logger,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start fitting our model to the data on see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=1024, num_workers=multiprocessing.cpu_count(), shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=1024, num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2000, 2020):\n",
    "    board, target_id, evaluation = dataset[i]\n",
    "    board = board.to(model.device)\n",
    "    board = board[None, :]\n",
    "    model.eval()\n",
    "    moves, score = model.forward(board)\n",
    "    print(f\"truth eval: {evaluation}\")\n",
    "    print(f\"predicted eval: {score}\")\n",
    "    print(f\"truth move: {target_id.argmax()}\")\n",
    "    print(f\"predicted move: {torch.topk(moves.flatten(), 5).indices} | prob: {moves[torch.topk(moves.flatten(), 5).indices]}\")\n",
    "\n",
    "model.save_model(\"models/model1.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('chessai-9CBJxCkL-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b4b484dc4462168a6fe1fe48525d5c69827656b86655a4bf6049a86e80fa9a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
